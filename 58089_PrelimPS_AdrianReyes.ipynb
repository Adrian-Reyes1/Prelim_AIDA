{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "58089_PrelimPS_AdrianReyes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adrian-Reyes1/Prelim_AIDA/blob/main/58089_PrelimPS_AdrianReyes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fte_zsqVdp8R"
      },
      "source": [
        "# Topic02a : Prelim Problem Set I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpcY5oJ5eFxA"
      },
      "source": [
        "## Case 1\n",
        "Represent the following representations into its vectorized form using LaTeX.\n",
        "> **Problem 1.a. System of Linear Equations**\n",
        "$$\n",
        "\\left\\{\n",
        "    \\begin{array}\\\\\n",
        "        -y+z=\\frac{1}{32}\\\\ \n",
        "        \\frac{1}{2}x -2y=0 \\\\\n",
        "        -x + \\frac{3}{7}z=\\frac{4}{5}\n",
        "    \\end{array}\n",
        "\\right. $$\n",
        "> **Problem 1.b. Linear Combination**\n",
        "$$  \\cos{(\\theta)}\\hat{i} + \\sin{(\\theta)}\\hat{j} - \\csc{(2\\theta)}\\hat{k}$$\n",
        "> **Problem 1.c. Scenario**\n",
        ">\n",
        ">A conference has 200 student attendees, 45 professionals, and has 15 members of the panel. There is a team of 40 people on the organizing committee. Represent the *percent* composition of each *attendee* type of the conference in matrix form.\n",
        "\n",
        "Express your answers in LaTeX in the answer area.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYPY0ZsMm-mk"
      },
      "source": [
        "**Problem 1.a** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP_PWDQHnQqt"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FfZNmpbn_0r",
        "outputId": "45002c06-5abb-4b7c-e1ab-9b22e68051f7"
      },
      "source": [
        "x = np.array([[-1, 1, 1/32], [1/2, -2, 0], [-1, 3/7, 4/5]])\n",
        "x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.        ,  1.        ,  0.03125   ],\n",
              "       [ 0.5       , -2.        ,  0.        ],\n",
              "       [-1.        ,  0.42857143,  0.8       ]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "096QGfVioFeq"
      },
      "source": [
        "$$\n",
        "x =\\begin{bmatrix} -1 & 1 & \\frac{1}{32} \\\\ \\frac{1}{2} & {-2} & 0\\\\ -1 & \\frac{3}{7} & \\frac{4}{5}\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibyN7efloKWX"
      },
      "source": [
        "**Problem 1.b**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fqFvAbaoNVa",
        "outputId": "338063ae-959a-4a5a-9672-ea056f15ab03"
      },
      "source": [
        "csc = 1/math.sin(2**180)\n",
        "cos = math.cos(180)\n",
        "sin = math.sin(180)\n",
        "\n",
        "t = np.array([cos, sin, csc]) ##Values from the upper part\n",
        "t"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.59846007, -0.80115264,  1.00032034])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3Xhdy9uoRqM"
      },
      "source": [
        "$$\n",
        "t =\\begin{bmatrix} cos{(\\theta)}\\hat{i} \\\\ sin{(\\theta)}\\hat{j}\\\\ -csc{(2\\theta)}\\hat{k}\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4G8j506oVrX"
      },
      "source": [
        "Problem 1.c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJTs7GQ0oaba",
        "outputId": "8f8939c3-46df-4c02-f728-eee4052b6619"
      },
      "source": [
        "attendees = np.array([200, 45, 15, 40])\n",
        "\n",
        "np.true_divide(attendees,300) * 100"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([66.66666667, 15.        ,  5.        , 13.33333333])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKlExY0Poh-4"
      },
      "source": [
        "$$\n",
        "\\begin{matrix} {Students} \\\\ {Professionals} \\\\ {Panels} \\\\ {Committee} \\end{matrix}\n",
        "\\begin{bmatrix} 200 \\\\ 45 \\\\ 15 \\\\ 40 \\end{bmatrix} =\n",
        "\\begin{bmatrix} 66.67\\% \\\\ 15.00\\% \\\\ 5.00\\% \\\\ 13.33\\% \\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvb1MGs9QNVt"
      },
      "source": [
        "# Case 2\n",
        "> **Problem 2.a: Vector Magnitude**\n",
        "\n",
        ">The magnitude of a vector is usually computed as:\n",
        "$$||v|| = \\sqrt{a_0^2 + a_1^2 + ... +a_n^2}$$\n",
        "Whereas $v$ is any vector and $a_k$ are its elements wherein $k$ is the size of $v$.\n",
        "Re-formulate $||v||$ as a function of an inner product. Further discuss this concept and provide your user-defined function.\n",
        "\n",
        "> **Problem 2.b: Angle Between Vectors**\n",
        "\n",
        "> Inner products can also be related to the Law of Cosines. The property suggests that:\n",
        "$$u\\cdot v = ||u||\\cdot||v||\\cos(\\theta)$$\n",
        "Whereas $u$ and $v$ are vectors that have the same sizes and $\\theta$ is the angle between $u$ and $v$.\n",
        "\n",
        "> Explain the behavior of the dot product when the two vectors are perpendicular and when they are parallel.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XvxJgmkooGq"
      },
      "source": [
        "**Problem 2.a**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NddEsTUwotkK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fgTUcaNoqDr"
      },
      "source": [
        "**Problem 2.b**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmRXzK8CouHP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cH8JpkBj1xS"
      },
      "source": [
        "# Case 3\n",
        "For the final cases analysis we will be looking at series of equations building up a single feed-forward computation of a logistic regression. The case will not require you to learn fully what is logistic regression. \n",
        "\n",
        "$$X = \\begin{bmatrix} \n",
        "— (x^{(1)})^T— \\\\ \n",
        "— (x^{(2)})^T— \\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T— \\\\\n",
        "\\end{bmatrix} \\text{, } \n",
        "Y = \\begin{bmatrix} \n",
        "y^{(1)} \\\\ \n",
        "y^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "y^{(m)} \\\\\n",
        "\\end{bmatrix} \\text{, and } \n",
        "\\theta = \\begin{bmatrix} \n",
        "\\theta^{(1)} \\\\ \n",
        "\\theta^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "\\theta^{(m)} \\\\\n",
        "\\end{bmatrix} $$\n",
        "The dataset $X$ has $m$ entries with $n$ features while $Y$ is the vector containing the groud truths of a the entries of $X$, and $\\theta$ are the parameters or weights of the vectors. We first compute the vector product of the dataset and the parameters as:\n",
        "$$ z = x^{(i)}\\theta^{(i)} = X\\cdot \\theta\\\\_{\\text{Eq. 3.1}}$$\n",
        "We then solve for the hypothesis of the logistic regression alogrithm as:\n",
        "\n",
        "$$ h_\\theta(x) = g(z)\\\\_{\\text{Eq. 3.2}}$$\n",
        "\n",
        "Where $g$ is an acitvation function that maps the values of the hypothesis vector between a range of 0 and 1. We computed the activation as a sigmoid function:\n",
        "$$g(z) = \\frac{1}{1+e^{-z}}\\\\_{\\text{Eq. 3.3}}$$\n",
        "Finally we compute the loss of the logistic regression algorithm using $J$. Wheras $J(\\theta)$ is a function that computes the logistic loss of the hypothesis with respect to the ground truths $y$. it is then computed as:\n",
        "$$J(\\theta) = \\frac{1}{m} \\sum^m_{i=0}=[-y^{(i)}\\log({h_{\\theta}(x^{(i)})})-(1-y^{(i)})\\log(1-h_{\\theta}(x^{(i)}))]\\\\_{\\text{Eq. 3.4}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ8jJV9-qyFy"
      },
      "source": [
        "> **Problem 3.a: Matrix Equivalences**\n",
        "\n",
        "> In Eq. 1, $z$ can also be solved as $X \\cdot \\theta$ which is the vectorized form of $x^{(i)}\\theta^{(i)}$. However, it can also be expressed as $\\theta^T\\cdot X$. Prove the equality of $X \\cdot \\theta$ with $\\theta^T\\cdot X$ in this case.\n",
        "\n",
        "> **Problem 3.b: Matrix Shapes**\n",
        "\n",
        "> Determine the shape of $h_\\theta$ if $X$ has a shape of $(300,5)$.\n",
        "\n",
        "> **Problem 3.c: Vectorization**\n",
        "\n",
        "> Express $J(\\theta)$ into its vectorized form.\n",
        "\n",
        "> **Problem 4.c: Computational Programming (Also Laboratory 2)**\n",
        "\n",
        "> Encode Equations 3.1 to 3.4 as the class `LRegression` wherein:\n",
        "\n",
        "> * `LRegression` should be instantiated with a dataset $X$, a ground truth vector $y$, and a parameter vector $\\theta$. Each parameter should have a data type of `numpy.array`.\n",
        "> * It should further have `methods`reflecting to at least the four (4) aforementioned equations. Each should have a return value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF3C6a4qW_LF"
      },
      "source": [
        "\n",
        "**Problem 3.a**\n",
        "> Unlike scalar multiplication, multiplication involving matrices is not commutative. However, commutative property is allowed when getting the dot product between two vectors.\n",
        "\n",
        "It means that $A\\cdot B = B \\cdot A $ can be applied even if one of the vectors is transposed. \n",
        "\n",
        "In problem 3.a, it is required to prove the equality of $X \\cdot \\theta$ with $\\theta^T\\cdot X$ given that $z$ can also be solved as $X \\cdot \\theta$ in equation 3.1\n",
        "$$X = \\begin{bmatrix} \n",
        "— (x^{(1)})^T— \\\\ \n",
        "— (x^{(2)})^T— \\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T— \\\\\n",
        "\\end{bmatrix} \\text{, } \n",
        "\\theta = \\begin{bmatrix} \n",
        "\\theta^{(1)} \\\\ \n",
        "\\theta^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "\\theta^{(m)} \\\\\n",
        "\\end{bmatrix} $$\n",
        "\n",
        "By computing the vector product of the dataset and the parameters $$ z = X\\cdot \\theta$$ we get:\n",
        "\n",
        "$$z = \\begin{bmatrix} \n",
        "— (x^{(1)})^T\\theta— \\\\ \n",
        "— (x^{(2)})^T\\theta-\\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T\\theta— \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "\n",
        ">By applying commutative property to $ z = X\\cdot \\theta$ which is the vectorized form of $x^{(i)^T} \\theta^{(i)}$ , we can say that it is equal to \n",
        "$$ z = \\theta^T\\cdot X$$ \n",
        "\n",
        "$$z = \\begin{bmatrix} \n",
        "—\\theta^T(x^{(1)})— \\\\ \n",
        "—\\theta^T(x^{(2)})-\\\\\n",
        "\\vdots \\\\\n",
        "—\\theta^T(x^{(m)})— \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Hence, \n",
        "$$z = \\begin{bmatrix} \n",
        "— (x^{(1)})^T\\theta— \\\\ \n",
        "— (x^{(2)})^T\\theta-\\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T\\theta— \\\\\n",
        "\\end{bmatrix} \n",
        "= \\begin{bmatrix} \n",
        "—\\theta^T(x^{(1)})— \\\\ \n",
        "—\\theta^T(x^{(2)})-\\\\\n",
        "\\vdots \\\\\n",
        "—\\theta^T(x^{(m)})— \\\\\n",
        "\\end{bmatrix} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGuTXvz1-NLP"
      },
      "source": [
        "\n",
        "**Problem 3.b**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ_OuAuEqPI0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpfsxheVpDzP"
      },
      "source": [
        "**Problem 3.c**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBgltiPypA-7"
      },
      "source": [
        "$$\\begin{bmatrix} \n",
        "\\frac{\\partial{J}}{\\partial{\\theta}_0} \\\\ \n",
        "\\frac{\\partial{J}}{\\partial{\\theta}_1} \\\\\n",
        "\\frac{\\partial{J}}{\\partial{\\theta}_2} \\\\\n",
        "\\vdots \\\\\n",
        "\\frac{\\partial{J}}{\\partial{\\theta}_n} \\\\\n",
        "\\end{bmatrix} = \n",
        "\\frac{1}{m}\n",
        "\\begin{bmatrix}  \n",
        "\\sum^{m}_{i=0}\\big[-y^{(i)}\\log\\big(h_{\\theta}\\big(x^{(i)}\\big)\\big)-\\big(1-y^{(i)}\\big)\\log(1-h_{\\theta}\\big(x{(i)}\\big)\\big]\\\\\n",
        "\\sum^{m}_{i=0}\\big[-y^{(i)}\\log\\big(h_{\\theta}\\big(x^{(i)}\\big)\\big)-\\big(1-y^{(i)}\\big)\\log(1-h_{\\theta}\\big(x{(i)}\\big)\\big]\\\\\n",
        "\\sum^{m}_{i=0}\\big[-y^{(i)}\\log\\big(h_{\\theta}\\big(x^{(i)}\\big)\\big)-\\big(1-y^{(i)}\\big)\\log(1-h_{\\theta}\\big(x{(i)}\\big)\\big]\\\\\n",
        "\\vdots\\\\\n",
        "\\sum^{m}_{i=0}\\big[-y^{(i)}\\log\\big(h_{\\theta}\\big(x^{(i)}\\big)\\big)-\\big(1-y^{(i)}\\big)\\log(1-h_{\\theta}\\big(x{(i)}\\big)\\big]\\\\\n",
        "\\end{bmatrix}\n",
        "\\\\\n",
        "$$"
      ]
    }
  ]
}